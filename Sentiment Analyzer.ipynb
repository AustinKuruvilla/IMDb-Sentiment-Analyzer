import nltk
from nltk.corpus import stopwords
from nltk.sentiment import SentimentIntensityAnalyzer
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.svm import SVC

# Download necessary NLTK resources (only required once)
nltk.download('vader_lexicon')
nltk.download('stopwords')
nltk.download('wordnet')

# Load labeled data for training a sentiment classifier
# Assumes the data is in the format: tweet,label (e.g., "I love this product,positive")
labeled_data = [
    ("I love this product", "positive"),
    ("This product is terrible", "negative"),
    ("The quality could be better", "neutral"),
    # Add more labeled data here...
]

# Preprocess the labeled data
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

preprocessed_data = []
labels = []

for tweet, label in labeled_data:
    tokens = word_tokenize(tweet.lower())
    filtered_tokens = [token for token in tokens if token not in stop_words]
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]
    preprocessed_tweet = ' '.join(lemmatized_tokens)
    
    preprocessed_data.append(preprocessed_tweet)
    labels.append(label)

# Split the preprocessed data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.2, random_state=42)

# Vectorize the preprocessed data using TF-IDF
vectorizer = TfidfVectorizer()
X_train_vectors = vectorizer.fit_transform(X_train)
X_test_vectors = vectorizer.transform(X_test)

# Train a Support Vector Machine (SVM) classifier
svm_classifier = SVC(kernel='linear')
svm_classifier.fit(X_train_vectors, y_train)

# Evaluate the trained classifier on the testing set
y_pred = svm_classifier.predict(X_test_vectors)
classification_report = classification_report(y_test, y_pred)
print("Classification Report:")
print(classification_report)

# Sentiment analysis of new, unseen tweets using Vader sentiment analyzer
unseen_tweets = [
    "This product exceeded my expectations!",
    "I'm really disappointed with the customer service.",
    "The price seems fair for the quality.",
    # Add more unseen tweets here...
]

analyzer = SentimentIntensityAnalyzer()

for tweet in unseen_tweets:
    sentiment_scores = analyzer.polarity_scores(tweet)
    print(f"Tweet: {tweet}")
    print(f"Sentiment Scores: {sentiment_scores}")
    print()
